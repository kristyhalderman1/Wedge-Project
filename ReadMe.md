
# Applied Data Analytics

## Wedge Project - Fall 2022 

![image](https://user-images.githubusercontent.com/112667258/205748782-db5fc70c-2c92-4b1a-af1b-604385459db7.png)


The Wedge Community Co-Op is a natural foods grocery store located in Minneapolis, Minnesota and the largest co-operative grocery store in the US.  During the course of the semester, our cohort had the opportunity to work with Wedge customer transaction data as a means to improve our analytical skillset and develop better business acumen.  This project is a culmination of those skills, where we break down what we have learned into various tasks. 

 
 
### Task 1: Upload the Files 


`File1 Name`: Wedge 1-Final .ipynb

In Task One, we uploaded transaction records to GBQ from Python (I worked with clean files).  First, I created a path to source the cleaned files (re: clean_files) and assigned to object 'clean_wedge_files,' then uploaded all the data into GBQ data set appropriately named 'wedge.' 



### Task 2: Sample of Owners 

`File2 Name`: Wedge-Part 2-Final.ipynb
In Task Two, we separate owners from non-owners (everyone is welcome at the Wedge!) and take a sample from a list of those owners since this will make it easier to analyze. 





	

### Task 3: Building Summary Tables 

`File3 Name`: Wedge-Part 3-Final.ipynb

Finally, for Task Three, we put those analytical skills to the test by building a SQLite database via Python which will contain three tables further diving into transactional data by examining sales by date by hour, sales by owner by year by month, and sales by product description by year by month.



## Query Comparison Results

Fill in the following table with the results from the 
queries contained in `gbq_assessment_query.sql`. You only
need to fill in relative difference on the rows where it applies. 
When calculating relative difference, use the formula 
` (your_results - john_results)/john_results)`. 



|  Query  |  Your Results  |  John's Results | Difference | Rel. Diff | 
|---|---|---|---|---|
| Total Rows  |   |   |   |   |
| January 2012 Rows  |   |   |   |   |
| October 2012 Rows  |   |   |   |   |
| Month with Fewest  |   |   | Yes/No  | NA  |
| Num Rows in Month with Fewest  |   |   |   |   |
| Month with Most  |   |   | Yes/No  | NA  |
| Num Rows in Month with Most  |   |   |   |   |
| Null_TS  |   |   |   |   |
| Null_DT  |   |   |   |   |
| Null_Local  |   |   |   |   |
| Null_CN  |   |   |   |   |
| Num 5 on High Volume Cards  |   |   | Yes/No  | NA  |
|  Num Rows for Number 5 |   |   |   |   |
| Num Rows for 18736  |   |   |   |   |
| Product with Most Rows  |   |   | Yes/No  | NA  |
| Num Rows for that Product  |   |   |   |   |
| Product with Fourth-Most Rows  |   |   | Yes/No  | NA  |
| Num Rows for that Product  |   |   |   |   |
| Num Single Record Products  |   |   |   |   |
| Year with Highest Portion of Owner Rows  |   |   | Yes/No  | NA |
| Fraction of Rows from Owners in that Year  |   |   |   |   |
| Year with Lowest Portion of Owner Rows  |   |   | Yes/No  | NA |
| Fraction of Rows from Owners in that Year  |   |   |   |   |

## Reflections

Overall, I thought this was a good way to 'sum up' what we did this semester and add to our portfolios!  If I were to do it again, I would look at the assignment day one and break down when I would learn each section and attempt it then instead of waiting until the final weeks of class to remember everything we did.  
